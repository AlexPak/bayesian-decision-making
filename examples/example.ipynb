{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ccad1c3-f23c-41eb-9db7-11bc994a3c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите значения для переменной x через запятую (по умолчанию [1, 2]): \n",
      "Введите значения для переменной y через запятую (по умолчанию [1, 2]): \n",
      "Введите значения для переменной z через запятую (по умолчанию [1, 2]): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating joint probability: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Присвоенные значения: {'x': 1, 'y': 1, 'z': 1}\n",
      "Совместная вероятность: 0.08\n",
      "Использованная память (в байтах): 552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import hashlib\n",
    "import sys\n",
    "from tqdm import tqdm  # Используется для отображения прогресса\n",
    "from typing import List, Dict, Tuple, Any\n",
    "\n",
    "class Variable:\n",
    "    def __init__(self, name: str, r: int):\n",
    "        self.name: str = name\n",
    "        self.r: int = r\n",
    "        self.values = list(range(1, r + 1))\n",
    "        self.prompt_user()\n",
    "\n",
    "    def prompt_user(self):\n",
    "        try:\n",
    "            user_values = input(f\"Введите значения для переменной {self.name} через запятую (по умолчанию {self.values}): \")\n",
    "            if user_values:\n",
    "                values = list(map(int, user_values.split(',')))\n",
    "                if len(values) == 1:\n",
    "                    self.values = list(range(1, values[0] + 1))\n",
    "                else:\n",
    "                    self.values = values\n",
    "        except ValueError:\n",
    "            print(f\"Используем стандартные значения для {self.name}: {self.values}\")\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "\n",
    "class Factor:\n",
    "    # TODO def __init__(self, vars: List[Variable], table: Dict[Tuple[Variable, int], float]):    \n",
    "    def __init__(self, vars: List[Variable], table: Dict[Tuple[str, int], float]):\n",
    "        self.vars = vars\n",
    "        self.table = table\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(tuple(self.vars))\n",
    "\n",
    "    def marginalization(self, var_name: str) -> 'Factor':\n",
    "        new_table = {}\n",
    "        for assignment, prob in self.table.items():\n",
    "            new_assignment = tuple((var, val) for var, val in assignment if var != var_name)\n",
    "            if new_assignment in new_table:\n",
    "                new_table[new_assignment] += prob\n",
    "            else:\n",
    "                new_table[new_assignment] = prob\n",
    "        new_vars = [var for var in self.vars if var.name != var_name]\n",
    "        return Factor(new_vars, new_table)\n",
    "    \n",
    "    # ToDo Unittest Example 3.2\n",
    "\n",
    "    def product(self, other: 'Factor') -> 'Factor':\n",
    "        new_vars = list(set(self.vars) | set(other.vars))\n",
    "        new_table = {}\n",
    "        for assignment1, prob1 in self.table.items():\n",
    "            for assignment2, prob2 in other.table.items():\n",
    "                merged_assignment = {**dict(assignment1), **dict(assignment2)}\n",
    "                new_table[tuple(merged_assignment.items())] = prob1 * prob2\n",
    "        return Factor(new_vars, new_table)\n",
    "    \n",
    "    # ToDo UnitTest Example 3.1\n",
    "    \n",
    "    # ToDo def Conditioning Algorithm 3.3 and UnitTest Example 3.3\n",
    "    \n",
    "    # ToDo def normalize():\n",
    "    \n",
    "\n",
    "class BayesianNetwork:\n",
    "    def __iself, vars: List[Variable], factors: List[Factor], edges: List[Tuple[int, int]]):\n",
    "        self.vars = vars\n",
    "        self.factors = factors\n",
    "        self.graph = nx.DiGraph(edges)\n",
    "\n",
    "    def probability(self, assignment: Dict[str, int]) -> float:\n",
    "        prob = 1.0\n",
    "        # Используем tqdm для отслеживания прогресса по факторам\n",
    "        for factor in tqdm(self.factors, desc=\"Calculating joint probability\"):\n",
    "            # Преобразуем подзадание в кортеж кортежей, чтобы соответствовать структуре ключей в таблице\n",
    "            sub_assignment = tuple([(var.name, assignment[var.name]) for var in factor.vars])\n",
    "            # Ищем вероятность в таблице фактора\n",
    "            prob *= factor.table.get(sub_assignment, 0.0)\n",
    "        return prob\n",
    "\n",
    "    # ToDo Develop testcase with assert Example 2.5 to check the probability func at class BayesianNetwork\n",
    "\n",
    "def hash_parameters_and_result(params: str, result: float) -> str:\n",
    "    hash_input = f\"Params: {params}, Result: {result}\"\n",
    "    hash_object = hashlib.sha256(hash_input.encode())\n",
    "    return hash_object.hexdigest()\n",
    "\n",
    "\n",
    "def calculate_memory_usage(variables: List[Variable], factors: List[Factor]) -> int:\n",
    "    \"\"\"\n",
    "    Подсчет используемой памяти для переменных и факторов.\n",
    "    \"\"\"\n",
    "    memory_usage = 0\n",
    "    for var in variables:\n",
    "        memory_usage += sys.getsizeof(var)\n",
    "    for factor in factors:\n",
    "        memory_usage += sys.getsizeof(factor)\n",
    "        memory_usage += sys.getsizeof(factor.table)\n",
    "    return memory_usage\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "X = Variable('x', 2)\n",
    "Y = Variable('y', 2)\n",
    "Z = Variable('z', 2)\n",
    "\n",
    "ϕ = Factor([X, Y, Z], {\n",
    "    (('x', 1), ('y', 1), ('z', 1)): 0.08, (('x', 1), ('y', 1), ('z', 2)): 0.31,\n",
    "    (('x', 1), ('y', 2), ('z', 1)): 0.09, (('x', 1), ('y', 2), ('z', 2)): 0.37,\n",
    "    (('x', 2), ('y', 1), ('z', 1)): 0.01, (('x', 2), ('y', 1), ('z', 2)): 0.05,\n",
    "    (('x', 2), ('y', 2), ('z', 1)): 0.02, (('x', 2), ('y', 2), ('z', 2)): 0.07\n",
    "})\n",
    "\n",
    "vars = [X, Y, Z]\n",
    "factors = [ϕ]\n",
    "edges = [(1, 2), (2, 3)]\n",
    "bn = BayesianNetwork(vars, factors, edges)\n",
    "\n",
    "assignment = {\n",
    "    'x': X.values[0],\n",
    "    'y': Y.values[0],\n",
    "    'z': Z.values[0]\n",
    "}\n",
    "\n",
    "# Подсчет вероятности и вывод прогресса\n",
    "probability_result = bn.probability(assignment)\n",
    "\n",
    "# Подсчет используемой памяти\n",
    "memory_usage = calculate_memory_usage(vars, factors)\n",
    "\n",
    "# Формирование строки параметров\n",
    "params_str = f\"x={assignment['x']}, y={assignment['y']}, z={assignment['z']}\"\n",
    "\n",
    "# Вывод хэша параметров и результата\n",
    "hash_value = hash_parameters_and_result(params_str, probability_result)\n",
    "\n",
    "print(f\"Присвоенные значения: {assignment}\")\n",
    "print(f\"Совместная вероятность: {probability_result}\")\n",
    "print(f\"Использованная память (в байтах): {memory_usage}\")\n",
    "# print(f\"Хэш параметров и результата: {hash_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eec7ccb-457c-4e38-909e-25c8fde4a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil  # Библиотека для получения системной информации\n",
    "\n",
    "def track_memory_usage():\n",
    "    \"\"\"\n",
    "    Возвращает текущее использование памяти в байтах.\n",
    "    \"\"\"\n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    return memory_info.rss  # Возвращает использование памяти в байтах\n",
    "\n",
    "def display_memory_usage(before: int, after: int):\n",
    "    \"\"\"\n",
    "    Отображает изменение использования памяти.\n",
    "    :param before: Использование памяти до выполнения задачи (в байтах).\n",
    "    :param after: Использование памяти после выполнения задачи (в байтах).\n",
    "    \"\"\"\n",
    "    used_memory = after - before\n",
    "    print(f\"Использование памяти до: {before / (1024 ** 2):.2f} MB\")\n",
    "    print(f\"Использование памяти после: {after / (1024 ** 2):.2f} MB\")\n",
    "    print(f\"Разница в использовании памяти: {used_memory / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac64b76f-5e6d-476a-9113-f9a531365e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating joint probability: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Calculating joint probability: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Calculating joint probability: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Calculating joint probability: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Calculating joint probability: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Calculating joint probability: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Calculating joint probability: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Calculating joint probability: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 1018.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Использование памяти до: 128.27 MB\n",
      "Использование памяти после: 128.32 MB\n",
      "Разница в использовании памяти: 0.05 MB\n",
      "Наилучшие присвоенные значения: {'x': 1, 'y': 2, 'z': 2}\n",
      "Наилучшая совместная вероятность: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Отслеживаем использование памяти до выполнения вероятностных расчетов\n",
    "snapshot_before = track_memory_usage()\n",
    "\n",
    "# Генерируем все возможные комбинации значений для переменных\n",
    "combinations = list(itertools.product(X.values, Y.values, Z.values))\n",
    "\n",
    "# Переменные для отслеживания наилучшей вероятности\n",
    "best_assignment = None\n",
    "best_probability = 0.0\n",
    "\n",
    "# Рассчитываем вероятность для каждой комбинации значений\n",
    "for combination in combinations:\n",
    "    assignment = {'x': combination[0], 'y': combination[1], 'z': combination[2]}\n",
    "    probability_result = bn.probability(assignment)\n",
    "    \n",
    "    if probability_result > best_probability:  # Сравниваем с наилучшей вероятностью\n",
    "        best_probability = probability_result\n",
    "        best_assignment = assignment\n",
    "\n",
    "# Отслеживаем использование памяти после выполнения вероятностных расчетов\n",
    "snapshot_after = track_memory_usage()\n",
    "\n",
    "# Отображение изменений в использовании памяти\n",
    "display_memory_usage(snapshot_before, snapshot_after)\n",
    "\n",
    "# Формирование строки параметров\n",
    "params_str = f\"x={best_assignment['x']}, y={best_assignment['y']}, z={best_assignment['z']}\"\n",
    "\n",
    "# Вывод хэша параметров и результата\n",
    "hash_value = hash_parameters_and_result(params_str, best_probability)\n",
    "\n",
    "print(f\"Наилучшие присвоенные значения: {best_assignment}\")\n",
    "print(f\"Наилучшая совместная вероятность: {best_probability}\")\n",
    "# print(f\"Хэш параметров и результата: {hash_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8526949b-6b23-4b7d-ba81-e53d88771777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Условное среднее: [0.5]\n",
      "Условная ковариация: [[0.75]]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Tuple, Any\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class ExactInference:\n",
    "    \"\"\"Класс для выполнения точного вывода.\"\"\"\n",
    "    \n",
    "    def infer(self, bn: Dict[str, Any], query: List[str], evidence: Dict[str, Any]) -> Factor:\n",
    "        \"\"\"\n",
    "        Выполняет точный вывод для Байесовской сети.\n",
    "        \n",
    "        Аргументы:\n",
    "            bn (Dict[str, Any]): Байесовская сеть с факторами и переменными.\n",
    "            query (List[str]): Переменные запроса.\n",
    "            evidence (Dict[str, Any]): Доказательства (условные переменные).\n",
    "        \n",
    "        Возвращает:\n",
    "            Factor: Нормализованный фактор для запроса.\n",
    "        \"\"\"\n",
    "        phi = prod(bn['factors'])\n",
    "        phi = condition(phi, **evidence)\n",
    "        \n",
    "        for var in set(phi.vars) - set(query):\n",
    "            phi = marginalize(phi, var)\n",
    "        \n",
    "        return normalize(phi)\n",
    "\n",
    "def infer_exact(inference: ExactInference, bn: Dict[str, Any], query: List[str], evidence: Dict[str, Any]) -> Factor:\n",
    "    \"\"\"\n",
    "    Выполняет точный вывод с использованием метода `ExactInference`.\n",
    "    \n",
    "    Аргументы:\n",
    "        inference (ExactInference): Метод точного вывода.\n",
    "        bn (Dict[str, Any]): Байесовская сеть с факторами и переменными.\n",
    "        query (List[str]): Переменные запроса.\n",
    "        evidence (Dict[str, Any]): Доказательства (условные переменные).\n",
    "    \n",
    "    Возвращает:\n",
    "        Factor: Нормализованный фактор для запроса.\n",
    "    \"\"\"\n",
    "    return inference.infer(bn, query, evidence)\n",
    "\n",
    "class VariableElimination:\n",
    "    \"\"\"Класс для выполнения вывода методом устранения переменных.\"\"\"\n",
    "    \n",
    "    def __init__(self, ordering: List[int]):\n",
    "        \"\"\"\n",
    "        Инициализация метода устранения переменных.\n",
    "        \n",
    "        Аргументы:\n",
    "            ordering (List[int]): Порядок устранения переменных.\n",
    "        \"\"\"\n",
    "        self.ordering = ordering\n",
    "\n",
    "def infer_variable_elimination(inference: VariableElimination, bn: Dict[str, Any], query: List[str], evidence: Dict[str, Any]) -> Factor:\n",
    "    \"\"\"\n",
    "    Выполняет вывод методом устранения переменных.\n",
    "    \n",
    "    Аргументы:\n",
    "        inference (VariableElimination): Метод устранения переменных.\n",
    "        bn (Dict[str, Any]): Байесовская сеть.\n",
    "        query (List[str]): Переменные запроса.\n",
    "        evidence (Dict[str, Any]): Доказательства.\n",
    "    \n",
    "    Возвращает:\n",
    "        Factor: Нормализованный результат вывода.\n",
    "    \"\"\"\n",
    "    phi_list = [condition(phi, **evidence) for phi in bn['factors']]\n",
    "    \n",
    "    for i in inference.ordering:\n",
    "        name = bn['vars'][i]\n",
    "        if name not in query:\n",
    "            inds = [j for j, phi in enumerate(phi_list) if name in phi.vars]\n",
    "            if inds:\n",
    "                phi = prod([phi_list[j] for j in inds])\n",
    "                phi_list = [phi_list[j] for j in range(len(phi_list)) if j not in inds]\n",
    "                phi = marginalize(phi, name)\n",
    "                phi_list.append(phi)\n",
    "    \n",
    "    return normalize(prod(phi_list))\n",
    "\n",
    "class DirectSampling:\n",
    "    \"\"\"Класс для выполнения прямого семплирования.\"\"\"\n",
    "    \n",
    "    def __init__(self, m: int):\n",
    "        \"\"\"\n",
    "        Инициализация метода прямого семплирования.\n",
    "        \n",
    "        Аргументы:\n",
    "            m (int): Количество семплов.\n",
    "        \"\"\"\n",
    "        self.m = m\n",
    "\n",
    "def infer_direct_sampling(inference: DirectSampling, bn: Dict[str, Any], query: List[str], evidence: Dict[str, Any]) -> Factor:\n",
    "    \"\"\"\n",
    "    Выполняет вывод методом прямого семплирования.\n",
    "    \n",
    "    Аргументы:\n",
    "        inference (DirectSampling): Метод прямого семплирования.\n",
    "        bn (Dict[str, Any]): Байесовская сеть.\n",
    "        query (List[str]): Переменные запроса.\n",
    "        evidence (Dict[str, Any]): Доказательства.\n",
    "    \n",
    "    Возвращает:\n",
    "        Factor: Нормализованный результат вывода.\n",
    "    \"\"\"\n",
    "    table = {}\n",
    "    \n",
    "    for _ in range(inference.m):\n",
    "        a = sample_bn(bn)\n",
    "        if all(a[k] == v for k, v in evidence.items()):\n",
    "            b = {k: a[k] for k in query}\n",
    "            table[b] = table.get(b, 0) + 1\n",
    "    \n",
    "    return normalize(Factor(list(query), table))\n",
    "\n",
    "class LikelihoodWeightedSampling:\n",
    "    \"\"\"Класс для выполнения семплирования с взвешиванием по правдоподобию.\"\"\"\n",
    "    \n",
    "    def __init__(self, m: int):\n",
    "        \"\"\"\n",
    "        Инициализация метода семплирования с взвешиванием по правдоподобию.\n",
    "        \n",
    "        Аргументы:\n",
    "            m (int): Количество семплов.\n",
    "        \"\"\"\n",
    "        self.m = m\n",
    "\n",
    "def infer_likelihood_weighted_sampling(inference: LikelihoodWeightedSampling, bn: Dict[str, Any], query: List[str], evidence: Dict[str, Any]) -> Factor:\n",
    "    \"\"\"\n",
    "    Выполняет вывод методом семплирования с взвешиванием по правдоподобию.\n",
    "    \n",
    "    Аргументы:\n",
    "        inference (LikelihoodWeightedSampling): Метод семплирования с взвешиванием по правдоподобию.\n",
    "        bn (Dict[str, Any]): Байесовская сеть.\n",
    "        query (List[str]): Переменные запроса.\n",
    "        evidence (Dict[str, Any]): Доказательства.\n",
    "    \n",
    "    Возвращает:\n",
    "        Factor: Нормализованный результат вывода.\n",
    "    \"\"\"\n",
    "    table = {}\n",
    "    \n",
    "    for _ in range(inference.m):\n",
    "        a, w = sample_weighted_bn(bn, evidence)\n",
    "        b = {k: a[k] for k in query}\n",
    "        table[b] = table.get(b, 0) + w\n",
    "    \n",
    "    return normalize(Factor(list(query), table))\n",
    "\n",
    "# Gibbs sampling\n",
    "class GibbsSampling:\n",
    "    def __init__(self, m_samples: int, m_burnin: int, m_skip: int, ordering: List[str]):\n",
    "        \"\"\"\n",
    "        Инициализация метода Гиббсова семплирования.\n",
    "\n",
    "        Аргументы:\n",
    "            m_samples (int): Количество семплов.\n",
    "            m_burnin (int): Количество начальных \"сожжённых\" семплов (burn-in period).\n",
    "            m_skip (int): Интервал между семплами.\n",
    "            ordering (List[str]): Порядок переменных для семплирования.\n",
    "        \"\"\"\n",
    "        self.m_samples = m_samples\n",
    "        self.m_burnin = m_burnin\n",
    "        self.m_skip = m_skip\n",
    "        self.ordering = ordering\n",
    "\n",
    "def gibbs_sample(a: Dict[str, Any], bn: Dict[str, Any], evidence: Dict[str, Any], ordering: List[str], steps: int) -> None:\n",
    "    \"\"\"\n",
    "    Выполняет несколько шагов Гиббсова семплирования для одной выборки.\n",
    "\n",
    "    Аргументы:\n",
    "        a (Dict[str, Any]): Текущая выборка переменных.\n",
    "        bn (Dict[str, Any]): Байесовская сеть.\n",
    "        evidence (Dict[str, Any]): Доказательства (условные переменные).\n",
    "        ordering (List[str]): Порядок переменных для обновления.\n",
    "        steps (int): Количество шагов для обновления.\n",
    "    \"\"\"\n",
    "    for _ in range(steps):\n",
    "        for var in ordering:\n",
    "            if var not in evidence:\n",
    "                # Обновить значение переменной `var`, используя условное распределение на основе других переменных\n",
    "                pass  # Здесь должна быть логика обновления переменной var на основе байесовской сети\n",
    "\n",
    "def infer_gibbs_sampling(inference: GibbsSampling, bn: Dict[str, Any], query: List[str], evidence: Dict[str, Any]) -> Factor:\n",
    "    \"\"\"\n",
    "    Выполняет вывод методом Гиббсова семплирования.\n",
    "\n",
    "    Аргументы:\n",
    "        inference (GibbsSampling): Метод Гиббсова семплирования.\n",
    "        bn (Dict[str, Any]): Байесовская сеть.\n",
    "        query (List[str]): Переменные запроса.\n",
    "        evidence (Dict[str, Any]): Доказательства.\n",
    "    \n",
    "    Возвращает:\n",
    "        Factor: Нормализованный результат вывода.\n",
    "    \"\"\"\n",
    "    table = {}\n",
    "    a = {**sample_bn(bn), **evidence}\n",
    "    \n",
    "    # Сожжение начальных семплов (burn-in)\n",
    "    gibbs_sample(a, bn, evidence, inference.ordering, inference.m_burnin)\n",
    "    \n",
    "    # Основной цикл выборки\n",
    "    for _ in range(inference.m_samples):\n",
    "        gibbs_sample(a, bn, evidence, inference.ordering, inference.m_skip)\n",
    "        b = {k: a[k] for k in query}\n",
    "        table[b] = table.get(b, 0) + 1\n",
    "    \n",
    "    return normalize(Factor(list(query), table))\n",
    "\n",
    "# Multivariate normal distribution\n",
    "def conditional_multivariate_normal(mean: np.ndarray, cov: np.ndarray, query_indices: List[int], evidence_indices: List[int], evidence: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Вычисляет условное распределение для многомерного нормального распределения.\n",
    "\n",
    "    Аргументы:\n",
    "        mean (np.ndarray): Среднее векторное значение для многомерного нормального распределения.\n",
    "        cov (np.ndarray): Ковариационная матрица.\n",
    "        query_indices (List[int]): Индексы переменных запроса.\n",
    "        evidence_indices (List[int]): Индексы переменных доказательств.\n",
    "        evidence (np.ndarray): Значения для переменных доказательств.\n",
    "    \n",
    "    Возвращает:\n",
    "        Tuple[np.ndarray, np.ndarray]: Условное среднее и ковариация для переменных запроса.\n",
    "    \"\"\"\n",
    "    b = evidence\n",
    "    mu_a = mean[query_indices]\n",
    "    mu_b = mean[evidence_indices]\n",
    "    A = cov[np.ix_(query_indices, query_indices)]\n",
    "    B = cov[np.ix_(evidence_indices, evidence_indices)]\n",
    "    C = cov[np.ix_(query_indices, evidence_indices)]\n",
    "    \n",
    "    # Условное среднее и ковариация\n",
    "    mu = mu_a + C @ np.linalg.inv(B) @ (b - mu_b)\n",
    "    Sigma = A - C @ np.linalg.inv(B) @ C.T\n",
    "    return mu, Sigma\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Пример условного многомерного нормального распределения\n",
    "    mean = np.array([0, 0])\n",
    "    cov = np.array([[1, 0.5], [0.5, 1]])\n",
    "    query_indices = [0]\n",
    "    evidence_indices = [1]\n",
    "    evidence = np.array([1])\n",
    "    \n",
    "    mu_conditional, Sigma_conditional = conditional_multivariate_normal(mean, cov, query_indices, evidence_indices, evidence)\n",
    "    print(\"Условное среднее:\", mu_conditional)\n",
    "    print(\"Условная ковариация:\", Sigma_conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd980be-2b75-4132-b1dc-086608d10479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multiply_factors(phi: Factor, psi: Factor) -> Factor:\n",
    "#     \"\"\"\n",
    "#     Перемножает два фактора (phi и psi) и возвращает новый фактор.\n",
    "    \n",
    "#     Аргументы:\n",
    "#         phi (Factor): Первый фактор.\n",
    "#         psi (Factor): Второй фактор.\n",
    "    \n",
    "#     Возвращает:\n",
    "#         Factor: Результат перемножения факторов phi и psi.\n",
    "#     \"\"\"\n",
    "#     phi_names = phi.vars\n",
    "#     psi_names = psi.vars\n",
    "#     psi_only = set(psi_names) - set(phi_names)\n",
    "    \n",
    "#     table = {}\n",
    "#     for phi_assignment, phi_prob in phi.table.items():\n",
    "#         for assignment in generate_assignments(psi_only):\n",
    "#             a = {**phi_assignment, **assignment}\n",
    "#             psi_assignment = {k: a[k] for k in psi_names}\n",
    "#             table[tuple(a.items())] = phi_prob * psi.table.get(psi_assignment, 0.0)\n",
    "    \n",
    "#     vars = list(phi.vars) + list(psi_only)\n",
    "#     return Factor(vars, table)\n",
    "\n",
    "# def marginalize(phi: Factor, name: str) -> Factor:\n",
    "#     \"\"\"\n",
    "#     Выполняет маргинализацию по переменной `name`, исключая её из фактора.\n",
    "    \n",
    "#     Аргументы:\n",
    "#         phi (Factor): Исходный фактор.\n",
    "#         name (str): Имя переменной, которую нужно исключить.\n",
    "    \n",
    "#     Возвращает:\n",
    "#         Factor: Новый фактор с исключённой переменной.\n",
    "#     \"\"\"\n",
    "#     table = {}\n",
    "#     for assignment, prob in phi.table.items():\n",
    "#         new_assignment = {k: v for k, v in assignment.items() if k != name}\n",
    "#         table[tuple(new_assignment.items())] = table.get(tuple(new_assignment.items()), 0.0) + prob\n",
    "    \n",
    "#     vars = [v for v in phi.vars if v != name]\n",
    "#     return Factor(vars, table)\n",
    "\n",
    "# def condition(phi: Factor, name: str, value: Any) -> Factor:\n",
    "#     \"\"\"\n",
    "#     Условная вероятность для переменной `name` с заданным значением `value`.\n",
    "    \n",
    "#     Аргументы:\n",
    "#         phi (Factor): Исходный фактор.\n",
    "#         name (str): Имя переменной.\n",
    "#         value (Any): Значение, которое принимает переменная.\n",
    "    \n",
    "#     Возвращает:\n",
    "#         Factor: Новый фактор, условный на переменной `name` с заданным значением.\n",
    "#     \"\"\"\n",
    "#     if name not in phi.vars:\n",
    "#         return phi\n",
    "    \n",
    "#     table = {}\n",
    "#     for assignment, prob in phi.table.items():\n",
    "#         if assignment[name] == value:\n",
    "#             new_assignment = {k: v for k, v in assignment.items() if k != name}\n",
    "#             table[tuple(new_assignment.items())] = prob\n",
    "    \n",
    "#     vars = [v for v in phi.vars if k != name]\n",
    "#     return Factor(vars, table)\n",
    "\n",
    "# def prod(factors: List[Factor]) -> Factor:\n",
    "#     \"\"\"\n",
    "#     Перемножает список факторов и возвращает результирующий фактор.\n",
    "    \n",
    "#     Аргументы:\n",
    "#         factors (List[Factor]): Список факторов для перемножения.\n",
    "    \n",
    "#     Возвращает:\n",
    "#         Factor: Результат перемножения всех факторов.\n",
    "#     \"\"\"\n",
    "#     result = factors[0]\n",
    "#     for factor in factors[1:]:\n",
    "#         result = multiply_factors(result, factor)\n",
    "#     return result\n",
    "\n",
    "# def normalize(phi: Factor) -> Factor:\n",
    "#     \"\"\"\n",
    "#     Нормализует фактор, чтобы сумма всех вероятностей была равна 1.\n",
    "    \n",
    "#     Аргументы:\n",
    "#         phi (Factor): Исходный фактор.\n",
    "    \n",
    "#     Возвращает:\n",
    "#         Factor: Нормализованный фактор.\n",
    "#     \"\"\"\n",
    "#     total = sum(phi.table.values())\n",
    "#     for key in phi.table:\n",
    "#         phi.table[key] /= total\n",
    "#     return phi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
